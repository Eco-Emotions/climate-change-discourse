{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba50cb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #Extract Tweet Data\n",
    "from tqdm.notebook import tqdm\n",
    "import snscrape.modules.twitter as sntwitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccf32b4",
   "metadata": {},
   "source": [
    "# Extract Tweet Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdd4b6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dengd\\AppData\\Local\\Temp\\ipykernel_7516\\1245425586.py:36: FutureWarning: content is deprecated, use rawContent instead\n",
      "  data = [tweet.date, tweet.content]\n",
      "Tweet 1110678088885501952 contains an app icon medium key '4_1630960288634908673' on app 'iphone_app'/'512393983', but the corresponding medium is missing; dropping\n",
      "Tweet 1110678088885501952 contains an app icon medium key '4_1630960288634908673' on app 'ipad_app'/'512393983', but the corresponding medium is missing; dropping\n",
      "Tweet 1164998403626901504 contains an app icon medium key '4_1630908911204306944' on app 'android_app'/'com.dd.doordash', but the corresponding medium is missing; dropping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped 246992 tweets.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "\n",
    "# Define keywords and date range\n",
    "climate_keywords = ['#climatechange', 'global warming', 'carbon footprint', 'greenhouse gas', 'climate crisis', 'climate action', 'sustainability', 'pollution', 'biodiversity', 'natural disasters', 'environmental policy']\n",
    "start_date = datetime.date(2017, 1, 1)\n",
    "end_date = datetime.date(2020, 1, 31)\n",
    "\n",
    "# Initialize list to store all tweets\n",
    "all_tweets = []\n",
    "\n",
    "# Loop over keywords and scrape tweets for each one\n",
    "for keyword in climate_keywords:\n",
    "    # Initialize list to store tweets for current keyword\n",
    "    keyword_tweets = []\n",
    "\n",
    "    # Loop over each day in the date range\n",
    "    delta = datetime.timedelta(days=1)\n",
    "    current_date = start_date\n",
    "    while current_date <= end_date:\n",
    "        # Define search query for current day and keyword\n",
    "        search_query = f'\"{keyword}\" since:{current_date} until:{current_date+delta}'\n",
    "\n",
    "        # Initialize daily count and list to store tweets for current day\n",
    "        daily_count = 0\n",
    "        daily_tweets = []\n",
    "\n",
    "        # Scrape tweets for current day and keyword\n",
    "        scraper = sntwitter.TwitterSearchScraper(search_query)\n",
    "        for tweet in scraper.get_items():\n",
    "            # Check if maximum daily limit is reached\n",
    "            if daily_count >= 20:\n",
    "                break\n",
    "\n",
    "            # Add tweet to daily list and increment daily count\n",
    "            data = [tweet.date, tweet.content]\n",
    "            daily_tweets.append(data)\n",
    "            daily_count += 1\n",
    "\n",
    "        # Add daily tweets for current keyword to list of all tweets\n",
    "        keyword_tweets.extend(daily_tweets)\n",
    "\n",
    "        # Move to next day\n",
    "        current_date += delta\n",
    "\n",
    "    # Add tweets for current keyword to all_tweets\n",
    "    all_tweets.extend(keyword_tweets)\n",
    "\n",
    "# Print the number of tweets scraped\n",
    "print(f\"Scraped {len(all_tweets)} tweets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7095d5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datetime\n",
    "# import snscrape.modules.twitter as sntwitter\n",
    "\n",
    "# # Define keywords and date range\n",
    "# climate_keywords = ['#climatechange', 'global warming', 'carbon footprint', 'greenhouse gas', 'climate crisis', 'climate action', 'sustainability', 'pollution', 'biodiversity', 'natural disasters', 'environmental policy']\n",
    "# start_date = datetime.date(2017, 1, 1)\n",
    "# end_date = datetime.date(2017, 1, 2)\n",
    "\n",
    "# # Initialize list to store all tweets\n",
    "# all_tweets = []\n",
    "\n",
    "# # Loop over keywords and scrape tweets for each one\n",
    "# for keyword in climate_keywords:\n",
    "#     search_query = f'\"{keyword}\" since:{start_date} until:{end_date}'\n",
    "#     scraper = sntwitter.TwitterSearchScraper(search_query)\n",
    "\n",
    "#     # Initialize list to store tweets for current keyword\n",
    "#     keyword_tweets = []\n",
    "\n",
    "#     # Scrape tweets for current keyword\n",
    "#     daily_count = 0\n",
    "#     prev_date = None\n",
    "#     for tweet in scraper.get_items():\n",
    "#         if prev_date is None:\n",
    "#             prev_date = tweet.date.date()\n",
    "#         if tweet.date.date() != prev_date:\n",
    "#             if daily_count >= 50:\n",
    "#                 print(f\"Reached max limit of 50 tweets per day for '{keyword}' before {prev_date}\")\n",
    "#                 break\n",
    "#             daily_count = 0\n",
    "#             prev_date = tweet.date.date()\n",
    "#         data = [tweet.date, tweet.id, tweet.content, tweet.user.username]\n",
    "#         keyword_tweets.append(data)\n",
    "#         daily_count += 1\n",
    "\n",
    "#     # Add tweets for current keyword to all_tweets\n",
    "#     all_tweets.extend(keyword_tweets)\n",
    "\n",
    "# # Print the number of tweets scraped\n",
    "# print(f\"Scraped {len(all_tweets)} tweets.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f2b795a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datetime\n",
    "# import snscrape.modules.twitter as sntwitter\n",
    "\n",
    "# # Define keyword and date range\n",
    "# climate_keywords = ['#climatechange','global warming', 'carbon footprint', 'greenhouse gas', 'climate crisis', 'climate action', 'sustainability', 'pollution', 'biodiversity', 'natural disasters', 'environmental policy']\n",
    "\n",
    "# # Define keywords\n",
    "# # climate_keywords = ['#climatechange', 'global warming', 'carbon footprint', 'greenhouse gas', 'climate crisis', 'climate action']\n",
    "\n",
    "# # Define start and end date for the search\n",
    "# start_date = datetime.date(2017, 1, 1)\n",
    "# end_date = datetime.date(2020, 1, 31)\n",
    "\n",
    "# # Define scraper for climate change keywords\n",
    "# search_query = '(climate change OR \"global warming\" OR \"carbon footprint\" OR \"greenhouse gas\" OR \"climate crisis\" OR \"climate action\" OR \"global warming\" OR \"carbon footprint\" OR \"greenhouse gas\" OR \"climate crisis\" OR \"climate action\") since:' + str(start_date) + ' until:' + str(end_date)\n",
    "# # search_query = 'climate action' + ' since:' + str(start_date) + ' until:' + str(end_date)\n",
    "# scraper = sntwitter.TwitterSearchScraper(search_query)\n",
    "\n",
    "# # Initialize lists to store the data\n",
    "# climate_tweets = []\n",
    "# daily_count = 0\n",
    "# prev_date = None\n",
    "\n",
    "# # Scrape tweets for climate change keywords\n",
    "# for i, tweet in enumerate(scraper.get_items()):\n",
    "#     if prev_date is None:\n",
    "#         prev_date = tweet.date.date()\n",
    "#     if tweet.date.date() != prev_date:\n",
    "#         if daily_count >= 50:\n",
    "#             print(f\"Reached max limit of 50 tweets per day on {prev_date}\")\n",
    "#             break\n",
    "#         daily_count = 0\n",
    "#         prev_date = tweet.date.date()\n",
    "#     data = [tweet.date, \n",
    "#             tweet.id, \n",
    "#             tweet.content, \n",
    "#             tweet.user.username]\n",
    "#     climate_tweets.append(data)\n",
    "#     daily_count += 1\n",
    "\n",
    "# # Print the number of tweets scraped\n",
    "# print(f\"Scraped {len(climate_tweets)} tweets.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "670c0c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datetime\n",
    "# import snscrape.modules.twitter as sntwitter\n",
    "\n",
    "# # Define keywords\n",
    "# climate_keywords = ['#climatechange', 'global warming', 'carbon footprint', 'greenhouse gas', 'climate crisis', 'climate action']\n",
    "\n",
    "# # Define start and end date for the search\n",
    "# start_date = datetime.date(2018, 2, 1)\n",
    "# end_date = datetime.date(2018, 2, 2)\n",
    "# # end_date = datetime.date.today()\n",
    "\n",
    "# # Define scraper for climate change and sustainability keywords\n",
    "# search_query = 'climate action' + ' since:' + str(start_date) + ' until:' + str(end_date) \n",
    "# #  search_query = ' OR '.join(climate_keywords) + ' since:' + str(start_date) + ' until:' + str(end_date)\n",
    "# scraper = sntwitter.TwitterSearchScraper(search_query)\n",
    "\n",
    "# # Scrape tweets for climate change and sustainability keywords\n",
    "# for i, tweet in enumerate(scraper.get_items()):\n",
    "#     data = [tweet.date, \n",
    "#             tweet.content]\n",
    "#     tweets.append(data)\n",
    "\n",
    "# # Print the number of tweets scraped\n",
    "# print(f\"Scraped {len(tweets)} tweets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4481024c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df = pd.DataFrame(all_tweets, columns =['date','content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11eb195f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01 23:59:23+00:00</td>\n",
       "      <td>#solarenergy #solarpower #Solarroof #Teslaroof...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-01 23:55:25+00:00</td>\n",
       "      <td>@realDonaldTrump Do you believe in #climatechange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-01 23:54:39+00:00</td>\n",
       "      <td>Belief in #ClimateChange, #IntelligenceAgencie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-01 23:54:19+00:00</td>\n",
       "      <td>US #Wisconsin—Dept Natural Resources' website ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-01 23:54:11+00:00</td>\n",
       "      <td>The latest GreenerRob's Daily! https://t.co/Yy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246987</th>\n",
       "      <td>2020-01-31 23:00:42+00:00</td>\n",
       "      <td>Don't let the Council on Environmental Quality...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246988</th>\n",
       "      <td>2020-01-31 23:00:00+00:00</td>\n",
       "      <td>Without the National Environmental Policy Act,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246989</th>\n",
       "      <td>2020-01-31 22:57:11+00:00</td>\n",
       "      <td>@SierraClub @bruneski Environmental Policy Act...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246990</th>\n",
       "      <td>2020-01-31 22:52:30+00:00</td>\n",
       "      <td>The National Environmental Policy Act is under...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246991</th>\n",
       "      <td>2020-01-31 22:49:54+00:00</td>\n",
       "      <td>The National Environmental Policy Act is under...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246992 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            date  \\\n",
       "0      2017-01-01 23:59:23+00:00   \n",
       "1      2017-01-01 23:55:25+00:00   \n",
       "2      2017-01-01 23:54:39+00:00   \n",
       "3      2017-01-01 23:54:19+00:00   \n",
       "4      2017-01-01 23:54:11+00:00   \n",
       "...                          ...   \n",
       "246987 2020-01-31 23:00:42+00:00   \n",
       "246988 2020-01-31 23:00:00+00:00   \n",
       "246989 2020-01-31 22:57:11+00:00   \n",
       "246990 2020-01-31 22:52:30+00:00   \n",
       "246991 2020-01-31 22:49:54+00:00   \n",
       "\n",
       "                                                  content  \n",
       "0       #solarenergy #solarpower #Solarroof #Teslaroof...  \n",
       "1       @realDonaldTrump Do you believe in #climatechange  \n",
       "2       Belief in #ClimateChange, #IntelligenceAgencie...  \n",
       "3       US #Wisconsin—Dept Natural Resources' website ...  \n",
       "4       The latest GreenerRob's Daily! https://t.co/Yy...  \n",
       "...                                                   ...  \n",
       "246987  Don't let the Council on Environmental Quality...  \n",
       "246988  Without the National Environmental Policy Act,...  \n",
       "246989  @SierraClub @bruneski Environmental Policy Act...  \n",
       "246990  The National Environmental Policy Act is under...  \n",
       "246991  The National Environmental Policy Act is under...  \n",
       "\n",
       "[246992 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddf87c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df.to_csv('climate_tweets.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc30e397",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
