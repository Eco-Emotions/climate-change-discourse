{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/the-reddit-climate-change-dataset-comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['subreddit.nsfw']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['subreddit.name'] = 'climatechange'\n",
    "df = df[~df['subreddit.nsfw']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['type', 'id', 'subreddit.id', 'permalink', 'subreddit.nsfw'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# light cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def text_light_clean(df):\n",
    "    # x = x.lower() # lowercase everything\n",
    "    df = df.encode('ascii', 'ignore').decode()  # remove unicode characters\n",
    "    df = re.sub(r'https*\\S+', ' ', df) # remove links\n",
    "    df = re.sub(r'http*\\S+', ' ', df) \n",
    "    \n",
    "    # cleaning up text\n",
    "    # x = re.sub(r'\\'\\w+', '', x) # Remove any contractions (e.g., \"don't\" becomes \"don\").\n",
    "    # x = re.sub(r'\\w*\\d+\\w*', '', x) # Remove any alphanumeric strings that contain numbers.\n",
    "    df = re.sub(r'\\s{2,}', ' ', df) # Replace any sequence of two or more whitespace characters with a single space.\n",
    "    df = re.sub(r'\\s[^\\w\\s]\\s', '', df) #  Remove any punctuation that is surrounded by whitespace characters.\n",
    "    \n",
    "    # deleting stop words    \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    df = ' '.join([word for word in df.split(' ') if word not in stop_words])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit.name</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>body</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>news</td>\n",
       "      <td>1661990368</td>\n",
       "      <td>Yeah but what the above commenter is saying is...</td>\n",
       "      <td>0.5719</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ohio</td>\n",
       "      <td>1661990340</td>\n",
       "      <td>Any comparison of efficiency between solar and...</td>\n",
       "      <td>-0.9877</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>newzealand</td>\n",
       "      <td>1661990327</td>\n",
       "      <td>I'm honestly waiting for climate change and th...</td>\n",
       "      <td>-0.1143</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sacramento</td>\n",
       "      <td>1661990278</td>\n",
       "      <td>Not just Sacramento. It's actually happening a...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>askreddit</td>\n",
       "      <td>1661990206</td>\n",
       "      <td>I think climate change tends to get some peopl...</td>\n",
       "      <td>0.6634</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600693</th>\n",
       "      <td>politics</td>\n",
       "      <td>1262349456</td>\n",
       "      <td>&amp;gt; We have no history - ours goes back only ...</td>\n",
       "      <td>-0.9849</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600694</th>\n",
       "      <td>askreddit</td>\n",
       "      <td>1262329541</td>\n",
       "      <td>Changing the oil *filter* every single time yo...</td>\n",
       "      <td>0.7579</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600695</th>\n",
       "      <td>environment</td>\n",
       "      <td>1262314480</td>\n",
       "      <td>A man who though a moderate Tory , has a mixed...</td>\n",
       "      <td>0.0242</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600696</th>\n",
       "      <td>worldnews</td>\n",
       "      <td>1262313018</td>\n",
       "      <td>Both Iggy and Harper would have marched us int...</td>\n",
       "      <td>0.4754</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600697</th>\n",
       "      <td>askreddit</td>\n",
       "      <td>1262306047</td>\n",
       "      <td>should be \"San Diego Weatherman has an opinion...</td>\n",
       "      <td>0.7998</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4585224 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        subreddit.name  created_utc  \\\n",
       "0                 news   1661990368   \n",
       "1                 ohio   1661990340   \n",
       "2           newzealand   1661990327   \n",
       "3           sacramento   1661990278   \n",
       "4            askreddit   1661990206   \n",
       "...                ...          ...   \n",
       "4600693       politics   1262349456   \n",
       "4600694      askreddit   1262329541   \n",
       "4600695    environment   1262314480   \n",
       "4600696      worldnews   1262313018   \n",
       "4600697      askreddit   1262306047   \n",
       "\n",
       "                                                      body  sentiment  score  \n",
       "0        Yeah but what the above commenter is saying is...     0.5719      2  \n",
       "1        Any comparison of efficiency between solar and...    -0.9877      2  \n",
       "2        I'm honestly waiting for climate change and th...    -0.1143      1  \n",
       "3        Not just Sacramento. It's actually happening a...     0.0000      4  \n",
       "4        I think climate change tends to get some peopl...     0.6634      1  \n",
       "...                                                    ...        ...    ...  \n",
       "4600693  &gt; We have no history - ours goes back only ...    -0.9849     32  \n",
       "4600694  Changing the oil *filter* every single time yo...     0.7579      3  \n",
       "4600695  A man who though a moderate Tory , has a mixed...     0.0242      1  \n",
       "4600696  Both Iggy and Harper would have marched us int...     0.4754      0  \n",
       "4600697  should be \"San Diego Weatherman has an opinion...     0.7998      1  \n",
       "\n",
       "[4585224 rows x 5 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4585224 entries, 0 to 4600697\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Dtype  \n",
      "---  ------          -----  \n",
      " 0   subreddit.name  object \n",
      " 1   created_utc     object \n",
      " 2   body            object \n",
      " 3   sentiment       float64\n",
      " 4   score           int64  \n",
      "dtypes: float64(1), int64(1), object(3)\n",
      "memory usage: 209.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['created_utc'] = pd.to_datetime(df['created_utc'], unit='s').dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit.name</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>body</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>news</td>\n",
       "      <td>2022-08-31</td>\n",
       "      <td>Yeah but what the above commenter is saying is...</td>\n",
       "      <td>0.5719</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ohio</td>\n",
       "      <td>2022-08-31</td>\n",
       "      <td>Any comparison of efficiency between solar and...</td>\n",
       "      <td>-0.9877</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>newzealand</td>\n",
       "      <td>2022-08-31</td>\n",
       "      <td>I'm honestly waiting for climate change and th...</td>\n",
       "      <td>-0.1143</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sacramento</td>\n",
       "      <td>2022-08-31</td>\n",
       "      <td>Not just Sacramento. It's actually happening a...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>askreddit</td>\n",
       "      <td>2022-08-31</td>\n",
       "      <td>I think climate change tends to get some peopl...</td>\n",
       "      <td>0.6634</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600693</th>\n",
       "      <td>politics</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>&amp;gt; We have no history - ours goes back only ...</td>\n",
       "      <td>-0.9849</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600694</th>\n",
       "      <td>askreddit</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>Changing the oil *filter* every single time yo...</td>\n",
       "      <td>0.7579</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600695</th>\n",
       "      <td>environment</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>A man who though a moderate Tory , has a mixed...</td>\n",
       "      <td>0.0242</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600696</th>\n",
       "      <td>worldnews</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>Both Iggy and Harper would have marched us int...</td>\n",
       "      <td>0.4754</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600697</th>\n",
       "      <td>askreddit</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>should be \"San Diego Weatherman has an opinion...</td>\n",
       "      <td>0.7998</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4585224 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        subreddit.name created_utc  \\\n",
       "0                 news  2022-08-31   \n",
       "1                 ohio  2022-08-31   \n",
       "2           newzealand  2022-08-31   \n",
       "3           sacramento  2022-08-31   \n",
       "4            askreddit  2022-08-31   \n",
       "...                ...         ...   \n",
       "4600693       politics  2010-01-01   \n",
       "4600694      askreddit  2010-01-01   \n",
       "4600695    environment  2010-01-01   \n",
       "4600696      worldnews  2010-01-01   \n",
       "4600697      askreddit  2010-01-01   \n",
       "\n",
       "                                                      body  sentiment  score  \n",
       "0        Yeah but what the above commenter is saying is...     0.5719      2  \n",
       "1        Any comparison of efficiency between solar and...    -0.9877      2  \n",
       "2        I'm honestly waiting for climate change and th...    -0.1143      1  \n",
       "3        Not just Sacramento. It's actually happening a...     0.0000      4  \n",
       "4        I think climate change tends to get some peopl...     0.6634      1  \n",
       "...                                                    ...        ...    ...  \n",
       "4600693  &gt; We have no history - ours goes back only ...    -0.9849     32  \n",
       "4600694  Changing the oil *filter* every single time yo...     0.7579      3  \n",
       "4600695  A man who though a moderate Tory , has a mixed...     0.0242      1  \n",
       "4600696  Both Iggy and Harper would have marched us int...     0.4754      0  \n",
       "4600697  should be \"San Diego Weatherman has an opinion...     0.7998      1  \n",
       "\n",
       "[4585224 rows x 5 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = pd.Timestamp('2017-01-01')\n",
    "end_date = pd.Timestamp('2020-02-01')\n",
    "mask = (df['created_utc'] >= start_date) & (df['created_utc'] < end_date)\n",
    "df = df.loc[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit.name</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>body</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005596</th>\n",
       "      <td>deepfatfried</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>I think he's the most honest, consistent, and ...</td>\n",
       "      <td>-0.7918</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005597</th>\n",
       "      <td>futurology</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>&amp;gt;No what I'm proposing is that if you actua...</td>\n",
       "      <td>0.6801</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005598</th>\n",
       "      <td>tefl</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>I think it definitely can be easier to get suc...</td>\n",
       "      <td>0.9440</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005599</th>\n",
       "      <td>climateskeptics</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>&amp;gt;Everything I am searching for keeps coming...</td>\n",
       "      <td>0.8385</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005600</th>\n",
       "      <td>thezoomergang</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>CLIMATE CHANGE ISNT FAKE AND WE NEED TO DO SOM...</td>\n",
       "      <td>0.3724</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3855159</th>\n",
       "      <td>politicaldiscussion</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Scientific opinion is not the same thing as ev...</td>\n",
       "      <td>-0.5346</td>\n",
       "      <td>-7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3855160</th>\n",
       "      <td>politics</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Yes, that evil coercion, ensuring that our gra...</td>\n",
       "      <td>0.4687</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3855161</th>\n",
       "      <td>latestagecapitalism</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>I had to unsub from that subreddit after a wee...</td>\n",
       "      <td>0.1280</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3855162</th>\n",
       "      <td>forwardsfromgrandma</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>CLIMATE CHANGE IS A HOAX ANDREW DUH!!!!!!!1!!!!</td>\n",
       "      <td>-0.5053</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3855163</th>\n",
       "      <td>politics</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>\"The website now states the cause of climate c...</td>\n",
       "      <td>0.9042</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1840121 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              subreddit.name created_utc  \\\n",
       "2005596         deepfatfried  2020-01-31   \n",
       "2005597           futurology  2020-01-31   \n",
       "2005598                 tefl  2020-01-31   \n",
       "2005599      climateskeptics  2020-01-31   \n",
       "2005600        thezoomergang  2020-01-31   \n",
       "...                      ...         ...   \n",
       "3855159  politicaldiscussion  2017-01-01   \n",
       "3855160             politics  2017-01-01   \n",
       "3855161  latestagecapitalism  2017-01-01   \n",
       "3855162  forwardsfromgrandma  2017-01-01   \n",
       "3855163             politics  2017-01-01   \n",
       "\n",
       "                                                      body  sentiment  score  \n",
       "2005596  I think he's the most honest, consistent, and ...    -0.7918      8  \n",
       "2005597  &gt;No what I'm proposing is that if you actua...     0.6801      1  \n",
       "2005598  I think it definitely can be easier to get suc...     0.9440      3  \n",
       "2005599  &gt;Everything I am searching for keeps coming...     0.8385      1  \n",
       "2005600  CLIMATE CHANGE ISNT FAKE AND WE NEED TO DO SOM...     0.3724      7  \n",
       "...                                                    ...        ...    ...  \n",
       "3855159  Scientific opinion is not the same thing as ev...    -0.5346     -7  \n",
       "3855160  Yes, that evil coercion, ensuring that our gra...     0.4687      7  \n",
       "3855161  I had to unsub from that subreddit after a wee...     0.1280     19  \n",
       "3855162    CLIMATE CHANGE IS A HOAX ANDREW DUH!!!!!!!1!!!!    -0.5053     31  \n",
       "3855163  \"The website now states the cause of climate c...     0.9042      3  \n",
       "\n",
       "[1840121 rows x 5 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yc/wft790592j143k8gw6c_18z40000gn/T/ipykernel_5559/4099411321.py:1: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_cleaned = pd.read_csv('data/clean_2017-2020_comments-climatechange.csv')\n"
     ]
    }
   ],
   "source": [
    "df_cleaned = pd.read_csv('data/clean_2017-2020_comments-climatechange.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit.name</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>score</th>\n",
       "      <th>Cleaned_Text</th>\n",
       "      <th>Datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deepfatfried</td>\n",
       "      <td>-0.7918</td>\n",
       "      <td>8.0</td>\n",
       "      <td>I think he is the most honest, consistent, and...</td>\n",
       "      <td>2020-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>futurology</td>\n",
       "      <td>0.6801</td>\n",
       "      <td>1.0</td>\n",
       "      <td>That would bring my sample size down to a meas...</td>\n",
       "      <td>2020-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tefl</td>\n",
       "      <td>0.944</td>\n",
       "      <td>3.0</td>\n",
       "      <td>I think it definitely can be easier to get suc...</td>\n",
       "      <td>2020-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>climateskeptics</td>\n",
       "      <td>0.8385</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Why? Because CO2 provides the largest forcing ...</td>\n",
       "      <td>2020-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thezoomergang</td>\n",
       "      <td>0.3724</td>\n",
       "      <td>7.0</td>\n",
       "      <td>CLIMATE CHANGE ISNT FAKE AND WE NEED TO DO SOM...</td>\n",
       "      <td>2020-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1750336</th>\n",
       "      <td>willis7737_news</td>\n",
       "      <td>-0.9849</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Ban Ki-moon buoyed by climate accord but lamen...</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1750337</th>\n",
       "      <td>politicaldiscussion</td>\n",
       "      <td>-0.5346</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>Scientific opinion is not the same thing as ev...</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1750338</th>\n",
       "      <td>politics</td>\n",
       "      <td>0.4687</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Yes, that evil coercion, ensuring that our gra...</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1750339</th>\n",
       "      <td>latestagecapitalism</td>\n",
       "      <td>0.128</td>\n",
       "      <td>19.0</td>\n",
       "      <td>I had to unsub from that subreddit after a wee...</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1750340</th>\n",
       "      <td>politics</td>\n",
       "      <td>0.9042</td>\n",
       "      <td>3.0</td>\n",
       "      <td>\"The website now states the cause of climate c...</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1750341 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              subreddit.name sentiment  score  \\\n",
       "0               deepfatfried   -0.7918    8.0   \n",
       "1                 futurology    0.6801    1.0   \n",
       "2                       tefl     0.944    3.0   \n",
       "3            climateskeptics    0.8385    1.0   \n",
       "4              thezoomergang    0.3724    7.0   \n",
       "...                      ...       ...    ...   \n",
       "1750336      willis7737_news   -0.9849    1.0   \n",
       "1750337  politicaldiscussion   -0.5346   -7.0   \n",
       "1750338             politics    0.4687    7.0   \n",
       "1750339  latestagecapitalism     0.128   19.0   \n",
       "1750340             politics    0.9042    3.0   \n",
       "\n",
       "                                              Cleaned_Text    Datetime  \n",
       "0        I think he is the most honest, consistent, and...  2020-01-31  \n",
       "1        That would bring my sample size down to a meas...  2020-01-31  \n",
       "2        I think it definitely can be easier to get suc...  2020-01-31  \n",
       "3        Why? Because CO2 provides the largest forcing ...  2020-01-31  \n",
       "4        CLIMATE CHANGE ISNT FAKE AND WE NEED TO DO SOM...  2020-01-31  \n",
       "...                                                    ...         ...  \n",
       "1750336  Ban Ki-moon buoyed by climate accord but lamen...  2017-01-01  \n",
       "1750337  Scientific opinion is not the same thing as ev...  2017-01-01  \n",
       "1750338  Yes, that evil coercion, ensuring that our gra...  2017-01-01  \n",
       "1750339  I had to unsub from that subreddit after a wee...  2017-01-01  \n",
       "1750340  \"The website now states the cause of climate c...  2017-01-01  \n",
       "\n",
       "[1750341 rows x 5 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pyLDAvis\n",
      "  Downloading pyLDAvis-3.4.0-py3-none-any.whl (2.6 MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.6 MB 3.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jinja2\n",
      "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 133 kB 29.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from pyLDAvis) (58.0.4)\n",
      "Requirement already satisfied: scipy in /Users/henrik/Library/Python/3.9/lib/python/site-packages (from pyLDAvis) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/henrik/Library/Python/3.9/lib/python/site-packages (from pyLDAvis) (1.2.0)\n",
      "Collecting funcy\n",
      "  Downloading funcy-1.18-py2.py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /Users/henrik/Library/Python/3.9/lib/python/site-packages (from pyLDAvis) (1.23.5)\n",
      "Collecting numexpr\n",
      "  Downloading numexpr-2.8.4-cp39-cp39-macosx_10_9_x86_64.whl (99 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 99 kB 23.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn>=1.0.0 in /Users/henrik/Library/Python/3.9/lib/python/site-packages (from pyLDAvis) (1.2.1)\n",
      "Collecting gensim\n",
      "  Downloading gensim-4.3.0-cp39-cp39-macosx_10_9_x86_64.whl (24.0 MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24.0 MB 21.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pandas>=1.3.4 in /Users/henrik/Library/Python/3.9/lib/python/site-packages (from pyLDAvis) (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/henrik/Library/Python/3.9/lib/python/site-packages (from pandas>=1.3.4->pyLDAvis) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/henrik/Library/Python/3.9/lib/python/site-packages (from pandas>=1.3.4->pyLDAvis) (2022.7.1)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas>=1.3.4->pyLDAvis) (1.15.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/henrik/Library/Python/3.9/lib/python/site-packages (from scikit-learn>=1.0.0->pyLDAvis) (3.1.0)\n",
      "Collecting FuzzyTM>=0.4.0\n",
      "  Downloading FuzzyTM-2.0.5-py3-none-any.whl (29 kB)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-6.3.0-py3-none-any.whl (56 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56 kB 6.4 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting pyfume\n",
      "  Downloading pyFUME-0.2.25-py3-none-any.whl (67 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67 kB 4.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting MarkupSafe>=2.0\n",
      "  Using cached MarkupSafe-2.1.2-cp39-cp39-macosx_10_9_x86_64.whl (13 kB)\n",
      "Collecting fst-pso\n",
      "  Downloading fst-pso-1.8.1.tar.gz (18 kB)\n",
      "Collecting simpful\n",
      "  Downloading simpful-2.10.0-py3-none-any.whl (31 kB)\n",
      "Collecting miniful\n",
      "  Downloading miniful-0.0.6.tar.gz (2.8 kB)\n",
      "Requirement already satisfied: requests in /Users/henrik/Library/Python/3.9/lib/python/site-packages (from simpful->pyfume->FuzzyTM>=0.4.0->gensim->pyLDAvis) (2.28.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/henrik/Library/Python/3.9/lib/python/site-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim->pyLDAvis) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/henrik/Library/Python/3.9/lib/python/site-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim->pyLDAvis) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/henrik/Library/Python/3.9/lib/python/site-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim->pyLDAvis) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/henrik/Library/Python/3.9/lib/python/site-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim->pyLDAvis) (3.4)\n",
      "Building wheels for collected packages: fst-pso, miniful\n",
      "  Building wheel for fst-pso (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fst-pso: filename=fst_pso-1.8.1-py3-none-any.whl size=20445 sha256=996d3e1bef6f11a66e27d3b2dd9ec49c8b4bce0e3b51252ba2df90fdfd0eb399\n",
      "  Stored in directory: /Users/henrik/Library/Caches/pip/wheels/99/66/48/d7ce0c6927f6abf167bbcdee537affc7b92c03632f78028411\n",
      "  Building wheel for miniful (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for miniful: filename=miniful-0.0.6-py3-none-any.whl size=3530 sha256=f44513f4d3db4c8f66824f5e03ec3d81cebdf31c9543ca4439d0180fec13e198\n",
      "  Stored in directory: /Users/henrik/Library/Caches/pip/wheels/d9/c7/71/db1d4646d963b34c530667501d3d6f34c0825eaffae2f0f2cb\n",
      "Successfully built fst-pso miniful\n",
      "Installing collected packages: miniful, simpful, fst-pso, pyfume, smart-open, MarkupSafe, FuzzyTM, numexpr, jinja2, gensim, funcy, pyLDAvis\n",
      "Successfully installed FuzzyTM-2.0.5 MarkupSafe-2.1.2 fst-pso-1.8.1 funcy-1.18 gensim-4.3.0 jinja2-3.1.2 miniful-0.0.6 numexpr-2.8.4 pyLDAvis-3.4.0 pyfume-0.2.25 simpful-2.10.0 smart-open-6.3.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting TextBlob\n",
      "  Downloading textblob-0.17.1-py2.py3-none-any.whl (636 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 636 kB 3.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: nltk>=3.1 in /Users/henrik/Library/Python/3.9/lib/python/site-packages (from TextBlob) (3.8.1)\n",
      "Requirement already satisfied: tqdm in /Users/henrik/Library/Python/3.9/lib/python/site-packages (from nltk>=3.1->TextBlob) (4.65.0)\n",
      "Requirement already satisfied: joblib in /Users/henrik/Library/Python/3.9/lib/python/site-packages (from nltk>=3.1->TextBlob) (1.2.0)\n",
      "Requirement already satisfied: click in /Users/henrik/Library/Python/3.9/lib/python/site-packages (from nltk>=3.1->TextBlob) (8.1.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/henrik/Library/Python/3.9/lib/python/site-packages (from nltk>=3.1->TextBlob) (2022.10.31)\n",
      "Installing collected packages: TextBlob\n",
      "Successfully installed TextBlob-0.17.1\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting wordcloud\n",
      "  Using cached wordcloud-1.8.2.2-cp39-cp39-macosx_10_9_x86_64.whl (160 kB)\n",
      "Requirement already satisfied: pillow in /Users/henrik/Library/Python/3.9/lib/python/site-packages (from wordcloud) (9.4.0)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.7.1-cp39-cp39-macosx_10_12_x86_64.whl (7.4 MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.4 MB 3.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.6.1 in /Users/henrik/Library/Python/3.9/lib/python/site-packages (from wordcloud) (1.23.5)\n",
      "Collecting pyparsing>=2.3.1\n",
      "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 98 kB 14.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cycler>=0.10\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.4.4-cp39-cp39-macosx_10_9_x86_64.whl (65 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65 kB 10.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.0.7-cp39-cp39-macosx_10_9_x86_64.whl (244 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 244 kB 19.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 965 kB 29.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting importlib-resources>=3.2.0\n",
      "  Downloading importlib_resources-5.12.0-py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/henrik/Library/Python/3.9/lib/python/site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/henrik/Library/Python/3.9/lib/python/site-packages (from matplotlib->wordcloud) (22.0)\n",
      "Collecting zipp>=3.1.0\n",
      "  Downloading zipp-3.15.0-py3-none-any.whl (6.8 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.15.0)\n",
      "Installing collected packages: zipp, pyparsing, kiwisolver, importlib-resources, fonttools, cycler, contourpy, matplotlib, wordcloud\n",
      "\u001b[33m  WARNING: The scripts fonttools, pyftmerge, pyftsubset and ttx are installed in '/Users/henrik/Library/Python/3.9/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script wordcloud_cli is installed in '/Users/henrik/Library/Python/3.9/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed contourpy-1.0.7 cycler-0.11.0 fonttools-4.38.0 importlib-resources-5.12.0 kiwisolver-1.4.4 matplotlib-3.7.1 pyparsing-3.0.9 wordcloud-1.8.2.2 zipp-3.15.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.12.2-py3-none-any.whl (293 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 293 kB 3.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: matplotlib!=3.6.1,>=3.1 in /Users/henrik/Library/Python/3.9/lib/python/site-packages (from seaborn) (3.7.1)\n",
      "Requirement already satisfied: pandas>=0.25 in /Users/henrik/Library/Python/3.9/lib/python/site-packages (from seaborn) (1.5.3)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.17 in /Users/henrik/Library/Python/3.9/lib/python/site-packages (from seaborn) (1.23.5)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/henrik/Library/Python/3.9/lib/python/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (5.12.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/henrik/Library/Python/3.9/lib/python/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/henrik/Library/Python/3.9/lib/python/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/henrik/Library/Python/3.9/lib/python/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/henrik/Library/Python/3.9/lib/python/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/henrik/Library/Python/3.9/lib/python/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/henrik/Library/Python/3.9/lib/python/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (22.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/henrik/Library/Python/3.9/lib/python/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/henrik/Library/Python/3.9/lib/python/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.4.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/henrik/Library/Python/3.9/lib/python/site-packages (from importlib-resources>=3.2.0->matplotlib!=3.6.1,>=3.1->seaborn) (3.15.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/henrik/Library/Python/3.9/lib/python/site-packages (from pandas>=0.25->seaborn) (2022.7.1)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.15.0)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.12.2\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import pickle\n",
    "import pyLDAvis.sklearn\n",
    "from collections import Counter\n",
    "from textblob import TextBlob\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation, NMF\n",
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned['Cleaned_Text'] = df_cleaned['Cleaned_Text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit.name</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>score</th>\n",
       "      <th>Cleaned_Text</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>our_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deepfatfried</td>\n",
       "      <td>-0.7918</td>\n",
       "      <td>8.0</td>\n",
       "      <td>I think he is the most honest, consistent, and...</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>0.180556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>futurology</td>\n",
       "      <td>0.6801</td>\n",
       "      <td>1.0</td>\n",
       "      <td>That would bring my sample size down to a meas...</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>-0.032285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tefl</td>\n",
       "      <td>0.944</td>\n",
       "      <td>3.0</td>\n",
       "      <td>I think it definitely can be easier to get suc...</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>0.162049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>climateskeptics</td>\n",
       "      <td>0.8385</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Why? Because CO2 provides the largest forcing ...</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>0.040152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thezoomergang</td>\n",
       "      <td>0.3724</td>\n",
       "      <td>7.0</td>\n",
       "      <td>CLIMATE CHANGE ISNT FAKE AND WE NEED TO DO SOM...</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    subreddit.name sentiment  score  \\\n",
       "0     deepfatfried   -0.7918    8.0   \n",
       "1       futurology    0.6801    1.0   \n",
       "2             tefl     0.944    3.0   \n",
       "3  climateskeptics    0.8385    1.0   \n",
       "4    thezoomergang    0.3724    7.0   \n",
       "\n",
       "                                        Cleaned_Text    Datetime  \\\n",
       "0  I think he is the most honest, consistent, and...  2020-01-31   \n",
       "1  That would bring my sample size down to a meas...  2020-01-31   \n",
       "2  I think it definitely can be easier to get suc...  2020-01-31   \n",
       "3  Why? Because CO2 provides the largest forcing ...  2020-01-31   \n",
       "4  CLIMATE CHANGE ISNT FAKE AND WE NEED TO DO SOM...  2020-01-31   \n",
       "\n",
       "   our_sentiment  \n",
       "0       0.180556  \n",
       "1      -0.032285  \n",
       "2       0.162049  \n",
       "3       0.040152  \n",
       "4      -0.500000  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned['our_sentiment'] = df_cleaned['Cleaned_Text'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 1750341 entries, 0 to 1750340\n",
      "Series name: our_sentiment\n",
      "Non-Null Count    Dtype  \n",
      "--------------    -----  \n",
      "1750341 non-null  float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 13.4 MB\n"
     ]
    }
   ],
   "source": [
    "df_cleaned['our_sentiment'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'our_sentiemnt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'our_sentiemnt'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plt\u001b[39m.\u001b[39mscatter(df_cleaned[\u001b[39m'\u001b[39m\u001b[39msentiment\u001b[39m\u001b[39m'\u001b[39m], df_cleaned[\u001b[39m'\u001b[39;49m\u001b[39mour_sentiemnt\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m      3\u001b[0m \u001b[39m# Add labels and title to the plot\u001b[39;00m\n\u001b[1;32m      4\u001b[0m plt\u001b[39m.\u001b[39mxlabel(\u001b[39m'\u001b[39m\u001b[39msentiment\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3807\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3808\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3809\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'our_sentiemnt'"
     ]
    }
   ],
   "source": [
    "plt.scatter(df_cleaned['sentiment'], df_cleaned['our_sentiemnt'])\n",
    "\n",
    "# Add labels and title to the plot\n",
    "plt.xlabel('sentiment')\n",
    "plt.ylabel('our_sentiment')\n",
    "plt.title('Correlation between col1 and col2: ' + str(corr))\n",
    "\n",
    "# Show the plot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bert Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/henrik/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from bertopic import BERTopic\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from bertopic import BERTopic\n",
    "#from sklearn.feature_extraction.text import CountVectorizer\n",
    "# we add this to remove stopwords, for lower volumes of data stopwords can cause issues\n",
    "#vectorizer_model = CountVectorizer(ngram_range=(1, 2), stop_words=\"english\")\n",
    "# deal with df if needed\n",
    "#text = df_cleaned['Cleaned_Text'].tolist()\n",
    "#model = BERTopic(\n",
    "    vectorizer_model=vectorizer_model,\n",
    "    language='english', calculate_probabilities=True,\n",
    "    verbose=True\n",
    ")\n",
    "topics, probs = model.fit_transform(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
