{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42ca753d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bertopic\n",
      "  Downloading bertopic-0.14.0-py2.py3-none-any.whl (119 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.9/119.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting hdbscan>=0.8.29\n",
      "  Downloading hdbscan-0.8.29.tar.gz (5.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn>=0.22.2.post1 in /opt/anaconda3/lib/python3.9/site-packages (from bertopic) (1.0.2)\n",
      "Requirement already satisfied: pandas>=1.1.5 in /opt/anaconda3/lib/python3.9/site-packages (from bertopic) (1.4.4)\n",
      "Requirement already satisfied: tqdm>=4.41.1 in /opt/anaconda3/lib/python3.9/site-packages (from bertopic) (4.64.1)\n",
      "Requirement already satisfied: plotly>=4.7.0 in /opt/anaconda3/lib/python3.9/site-packages (from bertopic) (5.9.0)\n",
      "Collecting sentence-transformers>=0.4.1\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting umap-learn>=0.5.0\n",
      "  Downloading umap-learn-0.5.3.tar.gz (88 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.2/88.2 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.20.0 in /opt/anaconda3/lib/python3.9/site-packages (from bertopic) (1.21.5)\n",
      "Requirement already satisfied: cython>=0.27 in /opt/anaconda3/lib/python3.9/site-packages (from hdbscan>=0.8.29->bertopic) (0.29.32)\n",
      "Requirement already satisfied: scipy>=1.0 in /opt/anaconda3/lib/python3.9/site-packages (from hdbscan>=0.8.29->bertopic) (1.9.1)\n",
      "Requirement already satisfied: joblib>=1.0 in /opt/anaconda3/lib/python3.9/site-packages (from hdbscan>=0.8.29->bertopic) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/anaconda3/lib/python3.9/site-packages (from pandas>=1.1.5->bertopic) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.9/site-packages (from pandas>=1.1.5->bertopic) (2022.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/anaconda3/lib/python3.9/site-packages (from plotly>=4.7.0->bertopic) (8.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.22.2.post1->bertopic) (2.2.0)\n",
      "Collecting transformers<5.0.0,>=4.6.0\n",
      "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torch>=1.6.0\n",
      "  Downloading torch-1.13.1-cp39-none-macosx_10_9_x86_64.whl (135.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.3/135.3 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading torchvision-0.14.1-cp39-cp39-macosx_10_9_x86_64.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nltk in /opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers>=0.4.1->bertopic) (3.7)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.97-cp39-cp39-macosx_10_9_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub>=0.4.0\n",
      "  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numba>=0.49 in /opt/anaconda3/lib/python3.9/site-packages (from umap-learn>=0.5.0->bertopic) (0.55.1)\n",
      "Collecting pynndescent>=0.5\n",
      "  Downloading pynndescent-0.5.8.tar.gz (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (4.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (21.3)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2.28.1)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (3.6.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (6.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.9/site-packages (from numba>=0.49->umap-learn>=0.5.0->bertopic) (63.4.1)\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /opt/anaconda3/lib/python3.9/site-packages (from numba>=0.49->umap-learn>=0.5.0->bertopic) (0.38.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas>=1.1.5->bertopic) (1.16.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (2022.7.9)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.2-cp39-cp39-macosx_10_11_x86_64.whl (3.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click in /opt/anaconda3/lib/python3.9/site-packages (from nltk->sentence-transformers>=0.4.1->bertopic) (8.0.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/anaconda3/lib/python3.9/site-packages (from torchvision->sentence-transformers>=0.4.1->bertopic) (9.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/anaconda3/lib/python3.9/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (3.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (1.26.11)\n",
      "Building wheels for collected packages: hdbscan, sentence-transformers, umap-learn, pynndescent\n",
      "  Building wheel for hdbscan (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for hdbscan: filename=hdbscan-0.8.29-cp39-cp39-macosx_10_9_x86_64.whl size=667098 sha256=a2b244aced1e5fc49605eaaba28ea1bc596cbc48f001e70d3d167fbb439e7153\n",
      "  Stored in directory: /Users/SimoneBroggini/Library/Caches/pip/wheels/05/6f/88/1a4c04276b98306f00217a1e300e6ba0252c6aa4f7616067ae\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125925 sha256=414d36fd90b6d989c94f9483a7802f334d9503bb9d037f8247c777ca82f8f9e6\n",
      "  Stored in directory: /Users/SimoneBroggini/Library/Caches/pip/wheels/71/67/06/162a3760c40d74dd40bc855d527008d26341c2b0ecf3e8e11f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for umap-learn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for umap-learn: filename=umap_learn-0.5.3-py3-none-any.whl size=82814 sha256=e2583b722a55feed861a90dbe3ab2c224d163ff392b0182b0352f4b7164d148a\n",
      "  Stored in directory: /Users/SimoneBroggini/Library/Caches/pip/wheels/f4/3e/1c/596d0a463d17475af648688443fa4846fef624d1390339e7e9\n",
      "  Building wheel for pynndescent (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pynndescent: filename=pynndescent-0.5.8-py3-none-any.whl size=55496 sha256=8929aefb0d0f57c6ba657910245e40c81842d94145588b12bbb6892c9c9a2fec\n",
      "  Stored in directory: /Users/SimoneBroggini/Library/Caches/pip/wheels/b9/89/cc/59ab91ef5b21dc2ab3635528d7d227f49dfc9169905dcb959d\n",
      "Successfully built hdbscan sentence-transformers umap-learn pynndescent\n",
      "Installing collected packages: tokenizers, sentencepiece, torch, torchvision, huggingface-hub, transformers, pynndescent, hdbscan, umap-learn, sentence-transformers, bertopic\n",
      "Successfully installed bertopic-0.14.0 hdbscan-0.8.29 huggingface-hub-0.12.1 pynndescent-0.5.8 sentence-transformers-2.2.2 sentencepiece-0.1.97 tokenizers-0.13.2 torch-1.13.1 torchvision-0.14.1 transformers-4.26.1 umap-learn-0.5.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#%pip install bertopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8a115db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d215022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "      <th>Cleaned_Text</th>\n",
       "      <th>length</th>\n",
       "      <th>Preprocessed_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm afraid climate change is going to kill me!...</td>\n",
       "      <td>Feeling scared? Have you been listening to or ...</td>\n",
       "      <td>Feeling scared Have you been listening to or r...</td>\n",
       "      <td>93</td>\n",
       "      <td>related concerns like answers even kill thread...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Let's use this space to discuss some of the mo...</td>\n",
       "      <td>Lets use this space to discuss some of the mos...</td>\n",
       "      <td>54</td>\n",
       "      <td>concerns pose free people structure well inclu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>&gt; Feeling scared? Have you been listening to o...</td>\n",
       "      <td>Feeling scared Have you been listening to or r...</td>\n",
       "      <td>33</td>\n",
       "      <td>one sources arent family vibes humanity infome...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>So I know this is a late response to this thre...</td>\n",
       "      <td>So I know this is a late response to this thre...</td>\n",
       "      <td>648</td>\n",
       "      <td>anxious scenario lot recap viewpoints like ass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>climate change isn't just going to pop up and ...</td>\n",
       "      <td>climate change isnt just going to pop up and m...</td>\n",
       "      <td>876</td>\n",
       "      <td>economic scenario embracing needed periods lot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>NaN</td>\n",
       "      <td>They are not floating.  What do you mean bin \"...</td>\n",
       "      <td>They are not floating What do you mean bin ant...</td>\n",
       "      <td>51</td>\n",
       "      <td>find sensitivity ecosystems floating thing cal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>NaN</td>\n",
       "      <td>According to Wikipedia, the free encyclopedia ...</td>\n",
       "      <td>According to Wikipedia the free encyclopedia t...</td>\n",
       "      <td>38</td>\n",
       "      <td>edit cocoa anyone removed cyanide ill wikipedi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Figure 30 has 100 MW installations at 0.94 per...</td>\n",
       "      <td>Figure has MW installations at per Watt fixed ...</td>\n",
       "      <td>32</td>\n",
       "      <td>doesnt different representation even axis youv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2500</th>\n",
       "      <td>NaN</td>\n",
       "      <td>There are lots of ways to reduce water lost to...</td>\n",
       "      <td>There are lots of ways to reduce water lost to...</td>\n",
       "      <td>38</td>\n",
       "      <td>lots edit reduce lost water solar ethods reduc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2501</th>\n",
       "      <td>NaN</td>\n",
       "      <td>There was a study with a compound in both coff...</td>\n",
       "      <td>There was a study with a compound in both coff...</td>\n",
       "      <td>35</td>\n",
       "      <td>less cocoa mg magnesium calcium loss would dep...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2502 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Title  \\\n",
       "0     I'm afraid climate change is going to kill me!...   \n",
       "1                                                   NaN   \n",
       "2                                                   NaN   \n",
       "3                                                   NaN   \n",
       "4                                                   NaN   \n",
       "...                                                 ...   \n",
       "2497                                                NaN   \n",
       "2498                                                NaN   \n",
       "2499                                                NaN   \n",
       "2500                                                NaN   \n",
       "2501                                                NaN   \n",
       "\n",
       "                                                   Text  \\\n",
       "0     Feeling scared? Have you been listening to or ...   \n",
       "1     Let's use this space to discuss some of the mo...   \n",
       "2     > Feeling scared? Have you been listening to o...   \n",
       "3     So I know this is a late response to this thre...   \n",
       "4     climate change isn't just going to pop up and ...   \n",
       "...                                                 ...   \n",
       "2497  They are not floating.  What do you mean bin \"...   \n",
       "2498  According to Wikipedia, the free encyclopedia ...   \n",
       "2499  Figure 30 has 100 MW installations at 0.94 per...   \n",
       "2500  There are lots of ways to reduce water lost to...   \n",
       "2501  There was a study with a compound in both coff...   \n",
       "\n",
       "                                           Cleaned_Text  length  \\\n",
       "0     Feeling scared Have you been listening to or r...      93   \n",
       "1     Lets use this space to discuss some of the mos...      54   \n",
       "2     Feeling scared Have you been listening to or r...      33   \n",
       "3     So I know this is a late response to this thre...     648   \n",
       "4     climate change isnt just going to pop up and m...     876   \n",
       "...                                                 ...     ...   \n",
       "2497  They are not floating What do you mean bin ant...      51   \n",
       "2498  According to Wikipedia the free encyclopedia t...      38   \n",
       "2499  Figure has MW installations at per Watt fixed ...      32   \n",
       "2500  There are lots of ways to reduce water lost to...      38   \n",
       "2501  There was a study with a compound in both coff...      35   \n",
       "\n",
       "                                      Preprocessed_Text  \n",
       "0     related concerns like answers even kill thread...  \n",
       "1     concerns pose free people structure well inclu...  \n",
       "2     one sources arent family vibes humanity infome...  \n",
       "3     anxious scenario lot recap viewpoints like ass...  \n",
       "4     economic scenario embracing needed periods lot...  \n",
       "...                                                 ...  \n",
       "2497  find sensitivity ecosystems floating thing cal...  \n",
       "2498  edit cocoa anyone removed cyanide ill wikipedi...  \n",
       "2499  doesnt different representation even axis youv...  \n",
       "2500  lots edit reduce lost water solar ethods reduc...  \n",
       "2501  less cocoa mg magnesium calcium loss would dep...  \n",
       "\n",
       "[2502 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('test_3.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2648c48",
   "metadata": {},
   "source": [
    "# Fitting BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fea11f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df.Preprocessed_Text.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07a7e3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model = BERTopic(embedding_model=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80e1000",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics, probs = topic_model.fit_transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43f57cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>4606</td>\n",
       "      <td>-1_the_and_to_climate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>313</td>\n",
       "      <td>0_paris_agreement_trump_president</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>291</td>\n",
       "      <td>1_london_police_protests_protesters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>226</td>\n",
       "      <td>2_weather_temperatures_extreme_record</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>219</td>\n",
       "      <td>3_he_him_his_think</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>107</td>\n",
       "      <td>11</td>\n",
       "      <td>107_primary_humans_wrong_cause</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>108</td>\n",
       "      <td>11</td>\n",
       "      <td>108_wine_beer_english_england</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>109</td>\n",
       "      <td>11</td>\n",
       "      <td>109_market_moreover_failure_economies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>110</td>\n",
       "      <td>11</td>\n",
       "      <td>110_filmed_dinner_suspended_field</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>111</td>\n",
       "      <td>10</td>\n",
       "      <td>111_south_incheon_report_korea</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Topic  Count                                   Name\n",
       "0       -1   4606                  -1_the_and_to_climate\n",
       "1        0    313      0_paris_agreement_trump_president\n",
       "2        1    291    1_london_police_protests_protesters\n",
       "3        2    226  2_weather_temperatures_extreme_record\n",
       "4        3    219                     3_he_him_his_think\n",
       "..     ...    ...                                    ...\n",
       "108    107     11         107_primary_humans_wrong_cause\n",
       "109    108     11          108_wine_beer_english_england\n",
       "110    109     11  109_market_moreover_failure_economies\n",
       "111    110     11      110_filmed_dinner_suspended_field\n",
       "112    111     10         111_south_incheon_report_korea\n",
       "\n",
       "[113 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c26377",
   "metadata": {},
   "source": [
    "## Preprocessed Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fdc93436",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pre = media_20.Preprocessed_Snippet.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d887279",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model_pre = BERTopic(embedding_model=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24135d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_pre, probs_pre = topic_model_pre.fit_transform(text_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66bd0216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>4788</td>\n",
       "      <td>-1_climate_change_global_warming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>353</td>\n",
       "      <td>0_paris_agreement_accord_president</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>332</td>\n",
       "      <td>1_care_health_gun_immigration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>291</td>\n",
       "      <td>2_london_police_protests_protest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>173</td>\n",
       "      <td>3_children_school_schools_kids</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>107</td>\n",
       "      <td>11</td>\n",
       "      <td>107_fracking_shale_underground_ban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>108</td>\n",
       "      <td>10</td>\n",
       "      <td>108_parties_voters_debacle_lose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>109</td>\n",
       "      <td>10</td>\n",
       "      <td>109_tillerson_rex_kelly_russia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>110</td>\n",
       "      <td>10</td>\n",
       "      <td>110_fuels_dioxide_fossil_avoid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>111</td>\n",
       "      <td>10</td>\n",
       "      <td>111_amazon_tool_flames_fires</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Topic  Count                                Name\n",
       "0       -1   4788    -1_climate_change_global_warming\n",
       "1        0    353  0_paris_agreement_accord_president\n",
       "2        1    332       1_care_health_gun_immigration\n",
       "3        2    291    2_london_police_protests_protest\n",
       "4        3    173      3_children_school_schools_kids\n",
       "..     ...    ...                                 ...\n",
       "108    107     11  107_fracking_shale_underground_ban\n",
       "109    108     10     108_parties_voters_debacle_lose\n",
       "110    109     10      109_tillerson_rex_kelly_russia\n",
       "111    110     10      110_fuels_dioxide_fossil_avoid\n",
       "112    111     10        111_amazon_tool_flames_fires\n",
       "\n",
       "[113 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model_pre.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff8aa1b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('paris', 0.05615720044842678),\n",
       " ('agreement', 0.03769333367947843),\n",
       " ('accord', 0.029603085714951155),\n",
       " ('president', 0.017190735459819386),\n",
       " ('trump', 0.01658042089513091),\n",
       " ('decision', 0.015128219779468556),\n",
       " ('states', 0.013183347897855064),\n",
       " ('united', 0.012892456219534377),\n",
       " ('pull', 0.01288050350263076),\n",
       " ('withdraw', 0.01241285834667872)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model_pre.get_topic(topic=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7bb427",
   "metadata": {},
   "source": [
    "## Tokenized Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "543816d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tok = media_20.Tokenized_Snippet.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5357f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model_tok = BERTopic(embedding_model=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b331c71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_tok, probs_tok = topic_model_tok.fit_transform(text_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce8e146a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>4946</td>\n",
       "      <td>-1_climate_change_global_warming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>344</td>\n",
       "      <td>0_australia_fires_wildfires_california</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>253</td>\n",
       "      <td>1_london_police_protests_protesters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>230</td>\n",
       "      <td>2_care_health_immigration_democrats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>180</td>\n",
       "      <td>3_paris_agreement_accord_decision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>106</td>\n",
       "      <td>11</td>\n",
       "      <td>106_enhanced_commitments_implemented_agreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>107</td>\n",
       "      <td>11</td>\n",
       "      <td>107_tucker_carlson_swamped_idiotic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>108</td>\n",
       "      <td>11</td>\n",
       "      <td>108_tomorrow_august_olivia_7th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>109</td>\n",
       "      <td>11</td>\n",
       "      <td>109_brexit_labour_services_election</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>110</td>\n",
       "      <td>10</td>\n",
       "      <td>110_children_grandchildren_beautiful_childbearing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Topic  Count                                               Name\n",
       "0       -1   4946                   -1_climate_change_global_warming\n",
       "1        0    344             0_australia_fires_wildfires_california\n",
       "2        1    253                1_london_police_protests_protesters\n",
       "3        2    230                2_care_health_immigration_democrats\n",
       "4        3    180                  3_paris_agreement_accord_decision\n",
       "..     ...    ...                                                ...\n",
       "107    106     11     106_enhanced_commitments_implemented_agreement\n",
       "108    107     11                 107_tucker_carlson_swamped_idiotic\n",
       "109    108     11                     108_tomorrow_august_olivia_7th\n",
       "110    109     11                109_brexit_labour_services_election\n",
       "111    110     10  110_children_grandchildren_beautiful_childbearing\n",
       "\n",
       "[112 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model_tok.get_topic_info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
